experiment_name: clip_fs_imagenet
pretrained_weights: vit_base_patch16_clip_224
model: vit
optimizer: adamw
epoch: 100
warmup_epoch: 10
lr_min: 1.0e-6
warmup_lr_init: 1.0e-7
batch_size: 256
test_batch_size: 208
momentum: 0.9
crop_size: 224
final_run: False
ft_attn_module: null
ft_attn_mode: parallel
ft_attn_ln: before
ft_mlp_module: null
ft_mlp_mode: parallel
ft_mlp_ln: before
adapter_bottleneck: 64
adapter_init: lora_kaiming
adapter_scaler: 0.1
convpass_bottleneck: 8
convpass_xavier_init: False
convpass_init: lora_xavier
convpass_scaler: 10
vpt_mode: null
vpt_num: 10
vpt_layer: null
vpt_dropout: 0.1
ssf: False
lora_bottleneck: 0
fact_dim: 8
fact_type: null
fact_scaler: 1.0
repadapter_bottleneck: 8
repadapter_init: lora_xavier
repadapter_scaler: 1
repadapter_group: 2
bitfit: False
vqt_num: 0
vqt_dropout: 0.1
mlp_index: null
mlp_type: full
attention_index: null
attention_type: full
ln: False
difffit: False
full: False
block_index: null
gpu_num: 1
debug: False
random_seed: 42
eval_freq: 1
early_patience: 10
data_path: data_folder
normalized: True
store_ckp: True
final_acc_hp: False
drop_path_rate: 0
merge_factor: 1