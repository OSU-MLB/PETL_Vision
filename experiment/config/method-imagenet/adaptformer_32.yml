"method_name": "adaptformer"
"ft_mlp_module": "adapter"
"ft_mlp_mode": "parallel"
"ft_mlp_ln": "before"
"adapter_init": "lora_kaiming"
"adapter_bottleneck": 32
"adapter_scaler": 0.1